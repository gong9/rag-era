/**
 * ReAct Agent æ ¸å¿ƒæ¨¡å—
 * å®ç° Agentic RAG æŸ¥è¯¢é€»è¾‘
 */
import { ReActAgent, Settings } from 'llamaindex';
import { configureLLM } from './config';
import { loadIndex } from './index-manager';
import { parseAgentOutput, fixMermaidFormat, type ToolCall } from './output-parser';
import { analyzeIntent, generateDirectResponse, shouldSkipAgent, intentTypes, type IntentType } from './intent-analyzer';
import { createToolContext, createAllTools, getToolCalls, getSearchResults } from './tools';
import { hybridSearch, formatSearchResults } from '../hybrid-search';
import { 
  preCheckFormat, 
  evaluateQuality, 
  buildEvaluationContext, 
  finalValidation 
} from './quality-evaluator';

/**
 * æ‰§è¡Œé“¾è·¯ï¼ˆç”¨äºè´¨é‡è¯„ä¼°ï¼‰
 */
interface ExecutionTrace {
  question: string;
  intent: {
    type: string;
    description: string;
    keywords: string[];
    suggestedTool: string | null;
  };
  preSearch: {
    executed: boolean;
    query: string;
    results: Array<{ docName: string; preview: string; score: number }>;
  };
  toolCalls: ToolCall[];
  answer: string;
}

/**
 * Agent æŸ¥è¯¢ç»“æœ
 */
export interface AgentQueryResult {
  answer: string;
  thinking: string[];
  sourceNodes: Array<{
    text: string;
    score: number;
    type: string;
    documentName?: string;
    metadata?: any;
  }>;
  retrievedContent?: string;
  toolCalls?: ToolCall[];
  isAgentic: boolean;
}

/**
 * System Prompt
 */
const SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çŸ¥è¯†åº“åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºç”¨æˆ·ä¸Šä¼ çš„çŸ¥è¯†åº“æ–‡æ¡£å›ç­”é—®é¢˜ã€‚

## å¯ç”¨å·¥å…·
1. search_knowledge - æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯èåˆï¼‰
2. deep_search - æ·±åº¦æ··åˆæ£€ç´¢ï¼ˆæ›´å¤šç»“æœï¼‰
3. keyword_search - å…³é”®è¯ç²¾ç¡®æœç´¢ï¼ˆé€‚åˆä¸“æœ‰åè¯ã€æ–‡ä»¶åï¼‰
4. graph_search - ğŸ†• çŸ¥è¯†å›¾è°±æ£€ç´¢ï¼ˆåŸºäºå®ä½“å…³ç³»ï¼Œé€‚åˆå¤æ‚é—®é¢˜ï¼‰
5. summarize_topic - è·å–æ–‡æ¡£åŸæ–‡ï¼ˆç”¨äºæ€»ç»“ï¼‰
6. web_search - ç½‘ç»œæœç´¢ï¼ˆä»…å½“çŸ¥è¯†åº“æ²¡æœ‰æ—¶ä½¿ç”¨ï¼‰
7. get_current_datetime - è·å–å½“å‰æ—¥æœŸæ—¶é—´
8. fetch_webpage - ç½‘é¡µæŠ“å–
9. generate_diagram - ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨

## æ„å›¾åˆ¤æ–­ä¸å·¥å…·é€‰æ‹©

**å…³ç³»æŸ¥è¯¢ï¼ˆæ¨èä½¿ç”¨ graph_searchï¼‰ï¼š**
- "è°æ˜¯xxxçš„ä¸Šçº§" / "Aå’ŒBæœ‰ä»€ä¹ˆå…³ç³»" / "xxxè´Ÿè´£ä»€ä¹ˆ" â†’ ä½¿ç”¨ graph_searchï¼ˆmode: localï¼‰
- æ¶‰åŠäººç‰©ã€ç»„ç»‡ã€äº‹ä»¶ä¹‹é—´å…³ç³»çš„é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨ graph_search

**æ–‡æ¡£/ä¹¦ç±æ€»ç»“ç±»é—®é¢˜ï¼š**
- "xxxè®²äº†ä»€ä¹ˆ" / "æ€»ç»“ä¸€ä¸‹xxx" â†’ ä½¿ç”¨ summarize_topic è·å–åŸæ–‡ï¼Œæˆ–ä½¿ç”¨ graph_searchï¼ˆmode: globalï¼‰

**ç²¾ç¡®æŸ¥æ‰¾ï¼ˆæ–‡ä»¶åã€ä»£ç ã€ä¸“æœ‰åè¯ï¼‰ï¼š**
- "æ‰¾åˆ° xxx.pdf" / "æœç´¢ function_name" â†’ ä½¿ç”¨ keyword_search

**è¯­ä¹‰æŸ¥è¯¢ï¼ˆæ¦‚å¿µã€å®šä¹‰ï¼‰ï¼š**
- "ä»€ä¹ˆæ˜¯xxx" / "å¦‚ä½•åšxxx" â†’ ä½¿ç”¨ search_knowledge æˆ– graph_search

**ç”»å›¾è¯·æ±‚ï¼ˆé‡è¦ï¼ï¼‰ï¼š**
- "ç”»ä¸ªxxxå›¾" / "æµç¨‹å›¾" / "æ—¶é—´å®‰æ’" â†’ ã€å¿…é¡»ã€‘å…ˆè°ƒç”¨ deep_search æˆ– summarize_topic è·å–è¯¦ç»†ä¿¡æ¯ï¼Œå†è°ƒç”¨ generate_diagram
- âš ï¸ å³ä½¿å·²æœ‰é¢„æ£€ç´¢å†…å®¹ï¼Œä¹Ÿå¿…é¡»è°ƒç”¨å·¥å…·è·å–æ›´å®Œæ•´çš„ä¿¡æ¯
- å›¾è¡¨è¦å°½å¯èƒ½è¯¦ç»†ï¼ŒåŒ…å«æ‰€æœ‰æ­¥éª¤å’Œç»†èŠ‚

**ç½‘ç»œæœç´¢ï¼ˆæœ€åæ‰‹æ®µï¼‰ï¼š**
- åªæœ‰å½“é—®é¢˜æ˜æ˜¾ä¸çŸ¥è¯†åº“æ— å…³æ—¶æ‰ä½¿ç”¨ web_search

## âš ï¸ é‡è¦è§„åˆ™
1. **å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ï¼ŒåŒ…æ‹¬æ— æ³•å›ç­”æ—¶ä¹Ÿå¿…é¡»ç”¨ä¸­æ–‡**
2. **ç¦æ­¢ä½¿ç”¨ä»»ä½•è‹±æ–‡å›å¤**ï¼ŒåŒ…æ‹¬ "Sorry, I cannot answer" è¿™ç±»
3. **å¦‚æœæ— æ³•å›ç­”ï¼Œè¯·è¯´"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¯·å°è¯•å…¶ä»–é—®æ³•æˆ–ä¸Šä¼ ç›¸å…³æ–‡æ¡£"**
4. **ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“å·¥å…·**ï¼Œç¦æ­¢è·³è¿‡æ£€ç´¢ç›´æ¥å›ç­”
5. **æ¶‰åŠå®ä½“æˆ–è€…å…³ç³»çš„é—®é¢˜ï¼Œä¼˜å…ˆä½¿ç”¨ graph_search**
6. å›ç­”è¦è¯¦ç»†ã€æœ‰æ¡ç†ï¼ŒåŸºäºçŸ¥è¯†åº“å†…å®¹
7. **ç”»å›¾å‰å¿…é¡»è°ƒç”¨ deep_search æˆ– summarize_topic** è·å–ä¿¡æ¯
8. å¦‚æœä½¿ç”¨äº†web_searchå·¥å…·ï¼Œè¯·åœ¨å›ç­”ä¸­è¯´æ˜æ˜¯ä½¿ç”¨äº†web_searchå·¥å…·è·å–çš„ä¿¡æ¯
`;

/**
 * æ™®é€š RAG æŸ¥è¯¢
 */
export async function query(
  knowledgeBaseId: string, 
  question: string,
  chatHistory: Array<{ role: 'user' | 'assistant'; content: string }> = [],
): Promise<any> {
  configureLLM();
  console.log(`[LLM] Query: "${question}" in KB ${knowledgeBaseId}`);
  console.log(`[LLM] Chat history: ${chatHistory.length} messages`);
  const startTime = Date.now();
  
  console.log(`[LLM] Loading index...`);
  const t1 = Date.now();
  const index = await loadIndex(knowledgeBaseId);
  console.log(`[LLM] Index loaded in ${Date.now() - t1}ms`);
  
  console.log(`[LLM] Creating query engine with topK=2...`);
  const t2 = Date.now();
  const queryEngine = index.asQueryEngine({
    similarityTopK: 2,
  });
  console.log(`[LLM] Query engine created in ${Date.now() - t2}ms`);

  // å¤„ç†å¯¹è¯å†å²
  let queryWithContext = question;
  if (chatHistory.length > 0) {
    const historyContext = chatHistory
      .slice(-6)
      .map(msg => `${msg.role === 'user' ? 'ç”¨æˆ·' : 'AI'}: ${msg.content}`)
      .join('\n');
    queryWithContext = `ä»¥ä¸‹æ˜¯ä¹‹å‰çš„å¯¹è¯å†å²ï¼š\n${historyContext}\n\nç”¨æˆ·å½“å‰é—®é¢˜ï¼š${question}\n\nè¯·æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡å›ç­”å½“å‰é—®é¢˜ã€‚`;
    console.log(`[LLM] Query with context length: ${queryWithContext.length} chars`);
  }

  console.log(`[LLM] Executing query...`);
  const t3 = Date.now();
  const response = await queryEngine.query({
    query: queryWithContext,
  });
  console.log(`[LLM] Query executed in ${Date.now() - t3}ms`);

  const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
  console.log(`[LLM] âœ… Query completed in ${totalTime}s`);
  console.log(`[LLM] Response length: ${response.response?.length || 0} chars`);
  console.log(`[LLM] Source nodes: ${response.sourceNodes?.length || 0}`);

  return {
    answer: response.response,
    sourceNodes: response.sourceNodes?.map((node: any) => ({
      text: node.node.text || node.node.getContent?.() || '',
      score: node.score,
      metadata: node.node.metadata,
    })),
  };
}

/**
 * Agentic RAG æŸ¥è¯¢
 */
export async function agenticQuery(
  knowledgeBaseId: string, 
  question: string,
  chatHistory: Array<{ role: 'user' | 'assistant'; content: string }> = [],
): Promise<AgentQueryResult> {
  configureLLM();
  console.log(`[LLM] Agentic Query: "${question}" in KB ${knowledgeBaseId}`);
  console.log(`[LLM] Chat history: ${chatHistory.length} messages`);
  const startTime = Date.now();

  // ========== ç¬¬ä¸€æ­¥ï¼šæ„å›¾åˆ¤æ–­ ==========
  console.log(`[LLM æ„å›¾] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
  console.log(`[LLM æ„å›¾] ğŸ¯ Step 1: Intent Analysis...`);
  
  const intentResult = await analyzeIntent(question, chatHistory);
  console.log(`[LLM æ„å›¾] ğŸ¯ Intent: ${intentResult.intent}`);
  console.log(`[LLM æ„å›¾] ğŸ¯ Needs KB: ${intentResult.needsKnowledgeBase}`);
  console.log(`[LLM æ„å›¾] ğŸ¯ Keywords: ${intentResult.keywords.join(', ')}`);
  console.log(`[LLM æ„å›¾] ğŸ¯ Suggested Tool: ${intentResult.suggestedTool || 'none'}`);
  
  // å¦‚æœæ˜¯é—²èŠ/é—®å€™ï¼Œç›´æ¥å›å¤
  if (shouldSkipAgent(intentResult.intent)) {
    console.log(`[LLM] ğŸ¯ Direct response for ${intentResult.intent}, skipping Agent`);
    const directResponse = await generateDirectResponse(question, intentResult.intent, chatHistory);
    return {
      answer: directResponse,
      thinking: [`ğŸ¯ æ„å›¾è¯†åˆ«: ${intentResult.intent}ï¼Œç›´æ¥å›å¤`],
      sourceNodes: [],
      isAgentic: true,
    };
  }
  
  console.log(`[LLM] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);

  // åŠ è½½ç´¢å¼•
  console.log(`[LLM] Loading index for agent...`);
  const index = await loadIndex(knowledgeBaseId);

  // åˆ›å»ºå·¥å…·ä¸Šä¸‹æ–‡å’Œå·¥å…·
  const toolContext = createToolContext(index, knowledgeBaseId);
  const tools = createAllTools(toolContext);
  
  console.log(`[LLM å·¥å…·ç”Ÿæˆ] Creating ReAct Agent with 9 tools...`);

  // ========== åˆå§‹åŒ–æ‰§è¡Œé“¾è·¯ ==========
  const trace: ExecutionTrace = {
    question,
    intent: {
      type: intentResult.intent,
      description: intentTypes[intentResult.intent as keyof typeof intentTypes] || 'æœªçŸ¥',
      keywords: intentResult.keywords,
      suggestedTool: intentResult.suggestedTool,
    },
    preSearch: {
      executed: false,
      query: '',
      results: [],
    },
    toolCalls: [],
    answer: '',
  };

  // ========== é¢„æ£€ç´¢çŸ¥è¯†åº“ ==========
  console.log(`[LLM] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€æ­£åœ¨é¢„æ£€ç´¢çŸ¥è¯†åº“â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
  let knowledgeContext = '';
  
  if (intentResult.needsKnowledgeBase) {
    console.log(`[LLM é¢„æ£€ç´¢] ğŸ“š Pre-fetching from knowledge base...`);
    
    const searchQuery = intentResult.keywords.length > 0 
      ? intentResult.keywords.join(' ') + ' ' + question
      : question;
    console.log(`[LLM é¢„æ£€ç´¢] ğŸ“š Search query: "${searchQuery}"`);
    
    trace.preSearch.executed = true;
    trace.preSearch.query = searchQuery;
    
    const results = await hybridSearch(index, knowledgeBaseId, searchQuery, {
      vectorTopK: 5,
      keywordLimit: 5,
    });
    
    if (results && results.length > 0) {
      // ä¿å­˜åˆ°å·¥å…·ä¸Šä¸‹æ–‡
      toolContext.searchResults.push(...results);
      
      console.log(`[LLM] ğŸ“š Found ${results.length} ç›¸å…³æ–‡æ¡£ (é¢„æ£€ç´¢ç»“æœ)`);
      const sources = results.map((result: any, i: number) => {
        const text = result.content || '';
        const docName = result.documentName || 'æœªçŸ¥æ–‡æ¡£';
        const score = parseFloat(result.score?.toFixed(3) || '0');
        console.log(`[LLM é¢„æ£€ç´¢] ğŸ“š   [${i + 1}] ${docName} (score: ${score})`);
        console.log(`[LLM é¢„æ£€ç´¢] ğŸ“š       ${text.substring(0, 100).replace(/\n/g, ' ')}...`);
        
        trace.preSearch.results.push({
          docName,
          preview: text.substring(0, 200),
          score,
        });
        
        return `[æ¥æº${i + 1}: ${docName}]\n${text.substring(0, 500)}`;
      });
      knowledgeContext = sources.join('\n\n');
    } else {
      console.log(`[LLM é¢„æ£€ç´¢] ğŸ“š No relevant documents found in knowledge base`);
    }
  } else {
    console.log(`[LLM é¢„æ£€ç´¢] ğŸ“š Skipping pre-fetch (intent: ${intentResult.intent})`);
  }
  console.log(`[LLM é¢„æ£€ç´¢] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);

  // æ„å»ºèƒŒæ™¯çŸ¥è¯†å¢å¼ºé—®é¢˜
  let enrichedQuestion = question;
  
  if (knowledgeContext) {
    enrichedQuestion = `## çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼ˆå¿…é¡»åŸºäºä»¥ä¸‹å†…å®¹å›ç­”ï¼‰ï¼š\n${knowledgeContext}\n\n`;
  }
  
  if (intentResult.suggestedTool) {
    enrichedQuestion += `## æ„å›¾åˆ†æï¼š\n- ç”¨æˆ·æ„å›¾: ${intentResult.intent}\n- å»ºè®®ä½¿ç”¨å·¥å…·: ${intentResult.suggestedTool}\n- å…³é”®è¯: ${intentResult.keywords.join(', ') || 'æ— '}\n\n`;
  }
  
  enrichedQuestion += `## ç”¨æˆ·é—®é¢˜ï¼š\n${question}\n\n`;
  
  // ç”»å›¾è¯·æ±‚ç‰¹æ®Šæç¤º
  if (intentResult.intent === 'draw_diagram') {
    enrichedQuestion += `âš ï¸ ã€ç”»å›¾è¯·æ±‚ç‰¹åˆ«è¯´æ˜ã€‘ï¼š
1. ä¸Šé¢çš„é¢„æ£€ç´¢å†…å®¹åªæ˜¯æ¦‚è¿°ï¼Œä¸å¤Ÿè¯¦ç»†
2. ä½ ã€å¿…é¡»ã€‘å…ˆè°ƒç”¨ deep_search æˆ– summarize_topic è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯
3. ç„¶åå°†è¯¦ç»†å†…å®¹ä½œä¸º description ä¼ ç»™ generate_diagram
4. å›¾è¡¨è¦å°½å¯èƒ½è¯¦ç»†ï¼ŒåŒ…å«æ‰€æœ‰æ­¥éª¤ã€æ—¶é—´ç‚¹ã€æ³¨æ„äº‹é¡¹ç­‰

`;
  }
  
  if (knowledgeContext) {
    enrichedQuestion += `è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“å†…å®¹ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚å¿…é¡»ä½¿ç”¨çŸ¥è¯†åº“å†…å®¹ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯ã€‚`;
  } else {
    enrichedQuestion += `è¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚`;
  }
  
  // è½¬æ¢å¯¹è¯å†å²
  const llamaHistory = chatHistory.slice(-6).map(msg => ({
    role: msg.role,
    content: msg.content,
  }));

  // åˆ›å»º Agent
  const agent = new ReActAgent({
    tools,
    systemPrompt: SYSTEM_PROMPT,
    chatHistory: llamaHistory,
    verbose: true,
  });

  // æ‰§è¡ŒæŸ¥è¯¢
  console.log(`[LLM Agentic] thinking and executing...`);
  const response = await agent.chat({ message: enrichedQuestion });

  const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
  console.log(`[LLM Agentic] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
  console.log(`[LLM Agentic] âœ… Agentic Query completed in ${totalTime}s`);
  
  // æ‰“å°åŸå§‹è¾“å‡º
  console.log(`[LLM Agentic] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
  console.log(`[LLM Agentic] æ¨ç†è¿‡ç¨‹`);
  console.log(`[LLM Agentic] ${response.response}`);
  console.log(`[LLM Agentic] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`);
  
  // æ‰“å°æ£€ç´¢åˆ°çš„æ–‡æ¡£
  // if (response.sourceNodes && response.sourceNodes.length > 0) {
  //   console.log(`[LLM Agentic] ğŸ“š Retrieved ${response.sourceNodes.length} source(s):`);
  //   response.sourceNodes.forEach((node: any, i: number) => {
  //     const text = node.node?.text || node.node?.getContent?.() || '';
  //     const preview = text.substring(0, 100).replace(/\n/g, ' ');
  //     console.log(`[LLM Agentic]   [${i + 1}] Score: ${node.score?.toFixed(3) || 'N/A'} | ${preview}...`);
  //   });
  // }

  // è§£æè¾“å‡º
  let { thinking, answer, toolCalls: parsedToolCalls } = parseAgentOutput(response.response || '');
  
  // åˆå¹¶å·¥å…·è°ƒç”¨è®°å½•
  const actualToolCalls = getToolCalls(toolContext);
  const toolCalls = actualToolCalls.length > 0 ? actualToolCalls : parsedToolCalls;
  
  trace.toolCalls = toolCalls;
  trace.answer = answer;
  
  console.log(`[LLM Agentic] Thinking length: ${thinking.length}`);
  console.log(`[LLM Agentic] Tool calls: ${toolCalls.length} (actual: ${actualToolCalls.length}, parsed: ${parsedToolCalls.length})`);
  toolCalls.forEach((call, i) => {
    console.log(`[LLM Agentic]   ğŸ”§ [${i + 1}] ${call.tool}(${call.input.substring(0, 50)}${call.input.length > 50 ? '...' : ''})`);
    if (call.output) {
      console.log(`[LLM Agentic]       â†’ ${call.output.substring(0, 80)}${call.output.length > 80 ? '...' : ''}`);
    }
  });
  console.log(`[LLM Agentic] Final answer: ${answer}`);


  // ========== æ ¼å¼é¢„æ£€æŸ¥ ==========
  const preCheck = preCheckFormat(answer, intentResult.intent as IntentType);
  if (preCheck.needsFix && preCheck.fixedAnswer) {
    answer = preCheck.fixedAnswer;
  }

  // ========== è´¨é‡è¯„ä¼° ==========
  const evalContext = buildEvaluationContext(
    trace.question,
    intentResult.intent as IntentType,
    answer,
    trace.toolCalls.map(c => c.tool),
    trace.preSearch.executed,
    trace.preSearch.results.length
  );
  
  const MAX_RETRIES = 3;
  let retryCount = 0;
  let qualityPassed = false;
  let lastIssue = '';
  
  while (!qualityPassed && retryCount < MAX_RETRIES) {
    console.log(`[LLM] ğŸ“Š Quality check (attempt ${retryCount + 1}/${MAX_RETRIES})...`);
    const evalResult = await evaluateQuality(answer, evalContext);
    
    if (evalResult.pass) {
      console.log(`[LLM] ğŸ“Š Quality: âœ… PASS`);
      qualityPassed = true;
    } else {
      lastIssue = evalResult.reason;
      console.log(`[LLM] ğŸ“Š Quality: âŒ FAIL - ${lastIssue}`);
      
      retryCount++;
      if (retryCount < MAX_RETRIES) {
        console.log(`[LLM] ğŸ“Š Retrying (${retryCount}/${MAX_RETRIES})...`);
        
        const retryMessage = `è¯·æ”¹è¿›ä½ çš„å›ç­”ã€‚

ã€é—®é¢˜ã€‘${lastIssue}

ã€åŸå§‹ç”¨æˆ·é—®é¢˜ã€‘${question}

ã€å·²çŸ¥ä¿¡æ¯ã€‘
${knowledgeContext || 'æ— é¢„æ£€ç´¢å†…å®¹'}

è¯·é‡æ–°ç”Ÿæˆï¼Œç‰¹åˆ«æ³¨æ„é€»è¾‘é¡ºåºï¼šå‰ç½®å‡†å¤‡â†’æ ¸å¿ƒæ­¥éª¤â†’åç»­å¤„ç†ã€‚
æ³¨æ„ï¼šè¯·ç›´æ¥åŸºäºå·²æœ‰ä¿¡æ¯å›ç­”ï¼Œä¸è¦è°ƒç”¨ç½‘ç»œæœç´¢å·¥å…·ã€‚`;
        
        const RETRY_TIMEOUT = 30000;
        try {
          const retryResponse = await Promise.race([
            agent.chat({ message: retryMessage }),
            new Promise<never>((_, reject) => 
              setTimeout(() => reject(new Error('Retry timeout')), RETRY_TIMEOUT)
            )
          ]);
          
          const retryParsed = parseAgentOutput(retryResponse.response || '');
          if (retryParsed.answer && retryParsed.answer.length > 50) {
            answer = retryParsed.answer;
            thinking = [...thinking, ...retryParsed.thinking];
            console.log(`[LLM] ğŸ“Š Retry done, new answer length: ${answer.length} chars`);
          } else {
            console.log(`[LLM] ğŸ“Š Retry failed, keeping previous answer`);
            break;
          }
        } catch (retryError: any) {
          console.log(`[LLM] ğŸ“Š Retry error: ${retryError.message}, keeping previous answer`);
          break;
        }
      }
    }
  }
  
  if (!qualityPassed) {
    console.log(`[LLM] ğŸ“Š Max retries reached, using last answer`);
  }
  
  // å…œåº•ï¼šé•¿åº¦è¶³å¤Ÿä¹Ÿé€šè¿‡
  if (!qualityPassed && answer.length > 100) {
    console.log(`[LLM] ğŸ“Š Fallback pass: answer length ${answer.length} > 100`);
    qualityPassed = true;
  }

  // ========== æœ€ç»ˆæ ¡éªŒ ==========
  const finalAnswer = finalValidation(answer, intentResult.intent as IntentType);

  // æ„å»º sourceNodes
  const searchResults = getSearchResults(toolContext);
  let sourceNodes: AgentQueryResult['sourceNodes'] = [];
  
  if (searchResults && searchResults.length > 0) {
    sourceNodes = searchResults.map((result: any) => ({
      text: result.content || '',
      score: result.score,
      type: result.source || 'hybrid',
      documentName: result.documentName,
    }));
  } else if (response.sourceNodes) {
    sourceNodes = response.sourceNodes.map((node: any) => ({
      text: node.node?.text || node.node?.getContent?.() || '',
      score: node.score,
      type: 'vector',
      metadata: node.node?.metadata,
    }));
  }
  
  return {
    answer: finalAnswer,
    thinking,
    sourceNodes,
    retrievedContent: knowledgeContext || '',
    toolCalls: trace.toolCalls,
    isAgentic: true,
  };
}

